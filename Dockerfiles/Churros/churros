#! /usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright(c) Ryuichiro Nakato <rnakato@iqb.u-tokyo.ac.jp>
# All rights reserved.

import os
import sys
import argparse
import pathlib
import pandas as pd
import re
import subprocess

__version__ = '1.5.1'

def print_and_exec_shell(command):
    print (command)
#    os.system(command)
    result = subprocess.run(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)

    if result.stdout:
        print(result.stdout)
    if result.stderr:
        print(result.stderr, file=sys.stderr)

    if result.returncode != 0 or re.search(r'Failed to process file', result.stderr, re.IGNORECASE) or re.search(r'error', result.stderr, re.IGNORECASE):
        print("Error: Command failed with error. Check your files and parameters.", file=sys.stderr)
        sys.exit(result.returncode)

def check_file(file):
    if os.path.isfile(file):
        pass
    else:
        print ("Error: " + file + " does not exist.")
        exit()

def check_dir(dir):
    if os.path.isdir(dir):
        pass
    else:
        print ("Error: " + dir + " does not exist.")
        exit()

def check_fastq_in_samplelist(samplelist):
    df = pd.read_csv(samplelist, sep=r'\s+',  header=None)
    df.fillna("", inplace=True)
    for index, row in df.iterrows():
        if (len(row)<2 or row[1] == ""):
            print (f"Error: Specify fastq file (or add line break at end) in {samplelist}.")
            exit()

        fq1 = row[1]
        for fastq in fq1.split(","):
            check_file(fastq)

        if (len(row)>2): # for paired-end
            fq2 = row[2]
            for fastq in fq2.split(","):
                check_file(fastq)

def check_duplicates(file_path):
    df = pd.read_csv(file_path, sep=r'\s+', header=None, names=['Col1', 'Col2'])

    duplicates_col1 = df['Col1'].duplicated(keep=False)
    duplicates_col2 = df['Col2'].duplicated(keep=False)

    if duplicates_col1.any():
        print("Warning: Duplicate found in column 1")
        print(df[duplicates_col1]['Col1'].value_counts())

    if duplicates_col2.any():
        print("Warning: Duplicate found in column 2")
        print(df[duplicates_col2]['Col2'].value_counts())


def do_fastqc(fastq, fastqcdir, fastpdir, ncore):
    prefix = os.path.basename(fastq).replace('.fastq', '').replace('.gz', '').replace('.fq', '')
    fastqc_output = fastqcdir + prefix + "_fastqc.zip"

    if os.path.isfile(fastqc_output):
        print (fastqc_output + " already created. skipping.")
    else:
        print_and_exec_shell(f'fastqc --threads {ncore} -o {fastqcdir} {fastq}')


def do_fastp(fq1, fq2, fastpdir, fastqtrimming, ncore):
    prefix = os.path.basename(fq1).replace('_R1.', '.').replace('_1.', '.').replace('.fastq', '').replace('.gz', '').replace('.fq', '')

    fastp_param = f"--thread {ncore} -q 20 --length_required 20 -n 5"
    if fq2 == "": # for single-end
        if fastqtrimming:
            fastp_output = f"{fastpdir}/{prefix}.trimmed.fastq.gz"
            if os.path.isfile(fastp_output):
                print (fastp_output + " already created. skipping.")
            else:
                print_and_exec_shell(f'fastp {fastp_param} -i {fq1} -h {fastpdir}/{prefix}.fastp.html -j {fastpdir}/{prefix}.fastp.json -o {fastp_output}')
        else:
            fastp_output = f"{fastpdir}/{prefix}.fastp.json"
            if os.path.isfile(fastp_output):
                print (fastp_output + " already created. skipping.")
            else:
                print_and_exec_shell(f'fastp {fastp_param} -i {fq1} -h {fastpdir}/{prefix}.fastp.html -j {fastpdir}/{prefix}.fastp.json')
    else: # for paired-end
        if fastqtrimming:
            fastp_output = f"{fastpdir}/{prefix}_1.trimmed.fastq.gz"
            fastp_output2 = f"{fastpdir}/{prefix}_2.trimmed.fastq.gz"
            if os.path.isfile(fastp_output):
                print (fastp_output + " already created. skipping.")
            else:
                print_and_exec_shell(f'fastp {fastp_param} -i {fq1} -I {fq2} -h {fastpdir}/{prefix}.fastp.html -j {fastpdir}/{prefix}.fastp.json -o {fastp_output} -O {fastp_output2}')

        else:
            fastp_output = f"{fastpdir}/{prefix}.fastp.json"
            if os.path.isfile(fastp_output):
                print (fastp_output + " already created. skipping.")
            else:
                print_and_exec_shell(f'fastp {fastp_param} -i {fq1} -I {fq2} -h {fastpdir}/{prefix}.fastp.html -j {fastpdir}/{prefix}.fastp.json ')


def do_readQC(chdir, build, samplelist, fastqtrimming, ncore):
    fastqcdir = chdir + "/fastqc/"
    fastpdir =  chdir + "/fastp/"
    os.makedirs(fastqcdir, exist_ok=True)
    os.makedirs(fastpdir, exist_ok=True)

    df = pd.read_csv(samplelist, sep=r'\s+',  header=None)
    df.fillna("", inplace=True)
    for index, row in df.iterrows():
        if (len(row)<2 or row[1] == ""):
            print (f"Error: Specify fastq file (or add line break at end) in {samplelist}.")
            exit()

        prefix = row[0]
        fq1 = row[1]
        for fastq in fq1.split(","):
            do_fastqc(fastq, fastqcdir, fastpdir, ncore)

        if (len(row)>2): # for paired-end
            fq2 = row[2]
            for fastq in fq2.split(","):
                do_fastqc(fastq, fastqcdir, fastpdir, ncore)

    for index, row in df.iterrows():
        if (len(row)<2 or row[1] == ""):
            print (f"Error: Specify fastq file (or add line break at end) in {samplelist}.")
            exit()

        prefix = row[0]
        fq1 = row[1]
        if (len(row)>2): # for paired-end
            fq2 = row[2]
            fq1s = fq1.split(",")
            fq2s = fq2.split(",")
            if len(fq1s) != len(fq2s):
                print (f"Error: the number of fastq files in {row[1]} and {row[2]} is not the same.")
                exit()
            for i, fq1 in enumerate(fq1s):
                fq2 = fq2s[i]
                do_fastp(fq1, fq2, fastpdir, fastqtrimming, ncore)
        else: # for single-end
            for fq1 in fq1.split(","):
                do_fastp(fq1, "", fastpdir, fastqtrimming, ncore)


def do_mapping_spikein(args, samplelist, samplepairlist, build, chdir):
    build_spikein = args.build_spikein
    Ddir_ref = args.Ddir
    Ddir_spikein = args.Ddir_spikein

    print ("Mapping with the spike-in mode.")

    if args.mapparam != "":
        mapparam = f"--bowtieparam \"{args.mapparam}\""
    else:
        mapparam = ""
    if args.parse2wigparam != "":
        parse2wigparam = f"--param_parse2wig \"{args.parse2wigparam}\""
    else:
        parse2wigparam = ""
    if args.nofilter:
        param_filter = "--nofilter"
    else:
        param_filter = ""

    if args.nompbl:
        param_churros_mapping = f"-D {chdir} -k {args.k} -p {args.threads} {mapparam} {param_filter} {parse2wigparam} --nompbl"
    else:
        param_churros_mapping = f"-D {chdir} -k {args.k} -p {args.threads} {mapparam} {param_filter} {parse2wigparam}"
    if args.spikein_simple:
        param_churros_mapping += f" --spikein_simple --spikein_constant {args.spikein_constant}"

    print_and_exec_shell(f'churros_mapping_spikein {param_churros_mapping} exec {samplelist} {samplepairlist} {build} {build_spikein} {Ddir_ref} {Ddir_spikein}')

    # stats
    qcstatsfile = f'{chdir}/{build}/churros.QCstats.tsv'
    os.system(f'churros_mapping_spikein {param_churros_mapping} header {samplelist} {samplepairlist} {build} {build_spikein} {Ddir_ref} {Ddir_spikein} > {qcstatsfile}')
    os.system(f'churros_mapping_spikein {param_churros_mapping} stats {samplelist} {samplepairlist} {build} {build_spikein} {Ddir_ref} {Ddir_spikein} >> {qcstatsfile}')
    # convert to xlsx
    os.system(f'csv2xlsx.pl -i {qcstatsfile} -o {chdir}/{build}/churros.QCstats.xlsx')


def do_mapping(args, samplelist, build, chdir, is_bam):
    print ("Mapping with the normal mode.")

    if args.mapparam != "":
        mapparam = f"-P \"{args.mapparam}\""
    else:
        mapparam = ""
    if args.parse2wigparam != "":
        parse2wigparam = f"-Q \"{args.parse2wigparam}\""
    else:
        parse2wigparam = ""
    if args.nofilter:
        param_filter = "-N"
    else:
        param_filter = ""
    if args.pair:
        param_pair = "-w"
    else:
        param_pair = ""

    if args.nompbl:
        param_churros_mapping = f"-D {chdir} -k {args.k} -p {args.threads} {mapparam} {param_filter} {param_pair} {parse2wigparam} -n"
    else:
        param_churros_mapping = f"-D {chdir} -k {args.k} -p {args.threads} {mapparam} {param_filter} {param_pair} {parse2wigparam}"

    if is_bam:
        print ("BAM files detected. Execute churros_mapping postprocess.")
        print_and_exec_shell(f'churros_mapping {param_churros_mapping} postprocess {samplelist} {build} {args.Ddir}')
        # stats
        qcstatsfile = f'{chdir}/{build}/churros.QCstats.tsv'
        os.system(f'churros_mapping {param_churros_mapping} header {samplelist} {build} {args.Ddir} > {qcstatsfile}')
        os.system(f'churros_mapping {param_churros_mapping} stats {samplelist} {build} {args.Ddir} >> {qcstatsfile}')
        # convert to xlsx
        os.system(f'csv2xlsx.pl -i {qcstatsfile} -o {chdir}/{build}/churros.QCstats.xlsx')
    else:
        print_and_exec_shell(f'churros_mapping {param_churros_mapping} exec {samplelist} {build} {args.Ddir}')
        # stats
        qcstatsfile = f'{chdir}/{build}/churros.QCstats.tsv'
        os.system(f'churros_mapping {param_churros_mapping} header {samplelist} {build} {args.Ddir} > {qcstatsfile}')
        os.system(f'churros_mapping {param_churros_mapping} stats {samplelist} {build} {args.Ddir} >> {qcstatsfile}')
        # convert to xlsx
        os.system(f'csv2xlsx.pl -i {qcstatsfile} -o {chdir}/{build}/churros.QCstats.xlsx')



def make_trimmedsamplelist(chdir, samplelist):
    samplelist_trimmed = chdir + "/samplelist.trimmed.txt"
    if(os.path.isfile(samplelist_trimmed)):
        os.remove(samplelist_trimmed)

    df = pd.read_csv(samplelist, sep=r'\s+',  header=None)
    df.fillna("", inplace=True)

    fastpdir =  chdir + "/fastp/"
    for index, row in df.iterrows():
        if (len(row)<3): # single-end
            label = row[0]
            fq1 = row[1]
            fq1s = fq1.split(",")
            for i, fq1 in enumerate(fq1s):
                prefix = os.path.basename(fq1).replace('_R1.', '.').replace('_1.', '.').replace('.fastq', '').replace('.gz', '').replace('.fq', '')
                fastp_output = f"{fastpdir}/{prefix}.trimmed.fastq.gz"
                os.system(f'echo "{label}\t{fastp_output}" >> {samplelist_trimmed}')

        else: # paired-end
            label = row[0]
            fq1 = row[1]
            fq2 = row[2]

            fq1s = fq1.split(",")
            fq2s = fq2.split(",")

            if len(fq1s) != len(fq2s):
                print (f"Error: the number of fastq files in {row[1]} and {row[2]} is not the same.")
                exit()

            for i, fq1 in enumerate(fq1s):
                fq2 = fq2s[i]
                prefix = os.path.basename(fq1).replace('_R1.', '.').replace('_1.', '.').replace('.fastq', '').replace('.gz', '').replace('.fq', '')
                fastp_output = f"{fastpdir}/{prefix}_1.trimmed.fastq.gz"
                fastp_output2 = f"{fastpdir}/{prefix}_2.trimmed.fastq.gz"
                os.system(f'echo "{label}\t{fastp_output}\t{fastp_output2}" >> {samplelist_trimmed}')

    check_fastq_in_samplelist(samplelist_trimmed)
    return samplelist_trimmed


def make_samplepairlist_withflen(samplepairlist, build, chdir):
    samplepairlist_withflen = chdir + "/churros.samplepairlist.withflen.txt"
    if(os.path.isfile(samplepairlist_withflen)):
        os.remove(samplepairlist_withflen)

    df = pd.read_csv(samplepairlist, sep=",", header=None, skip_blank_lines=True)
    df.fillna("", inplace=True)
    for index, row in df.iterrows():
        if all(str(cell).strip() == "" for cell in row):
            continue

        if len(row) < 4:
            print(f"Warning: Row {index + 1} has fewer than 4 non-empty columns. Skipping.")
            continue

        chip  = row[0]
        input = row[1]
        label = row[2]
        mode  = row[3]

        if chip == "":
            print(f"Warning: Skipping empty chip label in row {index + 1} of {samplepairlist}.")
            continue

        sspstats = pd.read_csv(chdir + '/sspout/' + chip + '.stats.txt', sep="\t", header=0)
        flen = int(sspstats["fragment length"])

        with open(samplepairlist_withflen, 'a') as f:
            print(f"{chip},{input},{label},{mode},{flen}", file=f)

    return samplepairlist_withflen


def ask_to_proceed_with_overwrite(filepath):
    """Produces a prompt asking about overwriting a file.

    # Arguments
        filepath: the path to the file to be overwritten.

    # Returns
        True if we can proceed with overwrite, False otherwise.
    """
    get_input = input
    if sys.version_info[:2] <= (2, 7):
        get_input = raw_input
    overwrite = get_input('[WARNING] the output directory "%s" already exists - overwrite? '
                          '[y/n]' % (filepath))
    while overwrite not in ['y', 'n']:
        overwrite = get_input('Enter "y" (overwrite) or "n" (cancel).')
    if overwrite == 'n':
        return False
    return True


def is_exist_input(samplepairlist):
    df = pd.read_csv(samplepairlist, sep=",", header=None)
    df.fillna("", inplace=True)

    nInput = 0
    for index, row in df.iterrows():
        chip  = row[0]
        input = row[1]
        label = row[2]

        if input != "":
            nInput += 1

    if nInput == 0:
        return False
    else:
        return True

def check_labels(samplelist, samplepairlist):
    with open(samplelist, 'r') as f:
        labels = set(re.split(r'\s+', line.strip())[0] for line in f)
    
    iserror = False
    with open(samplepairlist, 'r') as f:
        for line_number, line in enumerate(f, 1):
            row = line.strip().split(',')
            if (len(row)<2):
                print (f"Warning: Line {line_number} in {samplepairlist} is empty or has fewer than 2 columns. Skipping.")
                continue
            if row[0] != "" and row[0] not in labels:
                print (f"Error: Label '{row[0]}' in {samplepairlist} not found in {samplelist}.")
                iserror = True
            if row[1] != "" and row[1] not in labels:
                print (f"Error: Label '{row[1]}' in {samplepairlist} not found in {samplelist}.")
                iserror = True
    if iserror:
        exit()


def is_inputfile_BAM(samplelist):
    df = pd.read_csv(samplelist, sep=r'\s+',  header=None)
    df.fillna("", inplace=True)
    is_bam = False
    for index, row in df.iterrows():
        f = row[1]
        if f.endswith(".bam") or f.endswith(".sam") or f.endswith(".cram"):
            is_bam = True
            break

    return is_bam


def do_peakcall(args, samplelist, samplepairlist, build, chdir, chdir_build):
    ## make samplepairlist_withflen
    samplepairlist_withflen = make_samplepairlist_withflen(samplepairlist, build, chdir_build)

    ## churros_callpeak
    param_macs = f' -b bam -t {args.threads} -q {args.qval} -d {args.macsdir} -D {chdir}'

    if args.pair:
        param_pair = "-p"
    else:
        param_pair = ""

    df = pd.read_csv(samplelist, sep=r'\s+',  header=None)
    df.fillna("", inplace=True)
    for index, row in df.iterrows():
        if (len(row)>2): # for paired-end
            param_pair = "-p"

    if os.path.isfile(samplepairlist_withflen):
        print_and_exec_shell(f'churros_callpeak {param_macs} {param_pair} {samplepairlist_withflen} {build}')
    else:
        print_and_exec_shell(f'churros_callpeak {param_macs} {param_pair} {samplepairlist} {build}')


def exec_churros(args):
    samplelist = args.samplelist
    samplepairlist = args.samplepairlist
    build = args.build
    Ddir = args.Ddir
    chdir = args.outputdir
    chdir_build = chdir + "/" + build + "/"

    check_file(samplelist)
    check_file(samplepairlist)

    if os.path.isdir(chdir) and args.force != True:
        if ask_to_proceed_with_overwrite(chdir) == False:
            exit()

    # To absolute path
    samplelist = pathlib.Path(samplelist).resolve()
    samplepairlist = pathlib.Path(samplepairlist).resolve()

    # check samplelist
    check_fastq_in_samplelist(samplelist)
    check_duplicates(samplelist)
    check_labels(samplelist, samplepairlist)

#    post = get_mapfile_postfix(args.mapparam)
    gt = Ddir + '/genometable.txt'

    os.makedirs(chdir, exist_ok=True)

    ### in the case of BAM format for input files
    is_bam = is_inputfile_BAM(samplelist)

    ### FASTQC/FASTP
    if args.noqc == False and is_bam == False:
        do_readQC(chdir, build, samplelist, args.fastqtrimming, args.threads)

    if args.fastqtrimming and is_bam == False:
        samplelist_trimmed = make_trimmedsamplelist(chdir, samplelist)

    ## churros_mapping
    if args.fastqtrimming:
        if args.spikein:
            do_mapping_spikein(args, samplelist_trimmed, samplepairlist, build, chdir)
        else:
            do_mapping(args, samplelist_trimmed, build, chdir, is_bam)
    else:
        if args.spikein:
            do_mapping_spikein(args, samplelist, samplepairlist, build, chdir)
        else:
            do_mapping(args, samplelist, build, chdir, is_bam)


    do_peakcall(args, samplelist, samplepairlist, build, chdir, chdir_build)


    ## QC check
    if is_bam == False:
        print ("\nCheck the quality of ChIP-seq samples...\n")
        print_and_exec_shell(f'checkQC.py {chdir}/{build}/churros.QCstats.tsv {samplepairlist} | tee {chdir}/{build}/QCcheck.log')

    ### MultiQC
    print ("\n")
    print_and_exec_shell('multiqc -m fastqc -m fastp -m bowtie2 -m macs2 -f -o ' + chdir_build + ' ' + chdir)

    ### generate P-value bedGraph
    if args.outputpvalue:
        if args.nompbl:
            param_churros_genwig = " -n -D" + chdir + " "
        else:
            param_churros_genwig = " -D " + chdir + " "

        print ("\ngenerate Pvalue bedGraph file...")
        print_and_exec_shell('churros_genPvalwig ' + param_churros_genwig + str(samplepairlist) + ' bedGraph_Pval ' + build + ' ' + gt)

    ### make corremation heatmap
    if args.comparative:
        if args.nompbl:
            param_churros_compare = "-n -D" + chdir + " -p " + str(args.threads_comparative) + " "
        else:
            param_churros_compare = " -D " + chdir + " -p " + str(args.threads_comparative) + " "

        print_and_exec_shell('churros_compare ' + param_churros_compare + ' ' + str(samplelist) + ' ' + str(samplepairlist) + ' ' + build)

    ### make pdf files
    if args.spikein:
        do_visualize(args, chdir, build, samplepairlist, Ddir, args.spikein)
    do_visualize(args, chdir, build, samplepairlist, Ddir, False)

def do_visualize(args, chdir, build, samplepairlist, Ddir, is_spikein):
    print ("\ngenerate pdf files by drompa+...")

    if is_spikein:
        if args.spikein_simple:
            param_churros_visualize = f"-D {chdir} --pdfdir pdf_spikein --chipdirectory Spikein --inputdirectory TotalReadNormalized"
        else:
            param_churros_visualize = f"-D {chdir} --pdfdir pdf_spikein --chipdirectory Spikein --inputdirectory TotalReadNormalized"
        logfile = f"{chdir}/{build}/log/pdf_spikein/"
    else:
        param_churros_visualize = f"-D {chdir}"
        logfile = f"{chdir}/{build}/log/pdf/"
    if args.nompbl:
        param_churros_visualize += " --nompbl"
    if args.preset == "T2T":
        param_churros_visualize += " --preset T2T "
    if args.nofilter:
        param_churros_visualize += " --nofilter --pdfdir pdf_nofilter"

    print (f"The log files are in {logfile}")
    if args.preset == "scer":
        print_and_exec_shell(f'churros_visualize {param_churros_visualize} --preset scer --enrich {samplepairlist} drompa+.macspeak {build} {Ddir}')
        print_and_exec_shell(f'churros_visualize {param_churros_visualize} --preset scer --enrich --logratio {samplepairlist} drompa+.macspeak {build} {Ddir}')
    else:
        df = pd.read_csv(samplepairlist, sep=",", header=None)
        df.fillna("", inplace=True)

        if is_exist_input(samplepairlist):
            print_and_exec_shell(f'churros_visualize {param_churros_visualize} -b 5000 -l 8000 --pvalue -P "--pthre_enrich 3 --scale_pvalue 3" {samplepairlist} drompa+.pval.bin5M {build} {Ddir}')
            print_and_exec_shell(f'churros_visualize {param_churros_visualize} -G {samplepairlist} drompa+ {build} {Ddir}')

        print_and_exec_shell(f'churros_visualize {param_churros_visualize} {chdir}/{build}/{args.macsdir}/samplepairlist.txt drompa+.macspeak {build} {Ddir}')
        print_and_exec_shell(f'churros_visualize {param_churros_visualize} -b 5000 -l 8000 -P "--scale_tag 100" {samplepairlist} drompa+.bin5M {build} {Ddir}')


if(__name__ == '__main__'):
    parser = argparse.ArgumentParser()
    parser.add_argument("samplelist", help="Sample list", type=str)
    parser.add_argument("samplepairlist", help="ChIP/Input pair list", type=str)
    parser.add_argument("build", help="Genome build (e.g., hg38)", type=str)
    parser.add_argument("Ddir", help="Directory of reference data", type=str)
    parser.add_argument("--cram", help="Output as CRAM format (default: BAM)", action="store_true")
    parser.add_argument("-f", "--force", help="Overwrite if the output directory already exists", action="store_true")
    parser.add_argument("-b", "--binsize", help="Binsize of parse2wig+ (default: 100)", type=int, default=100)
    parser.add_argument("-k", help="Read length for mappability file ([28|36|50], default:50)", type=int, default=50)
    parser.add_argument("--nompbl", help="Do not consider genome mappability in drompa+", action="store_true")
    parser.add_argument("--nofilter", help="Do not filter PCR duplicate", action="store_true")
    parser.add_argument("--noqc", help="Omit FASTQC and fastp", action="store_true")
    parser.add_argument("--fastqtrimming", help="Apply adapter trimming with fastp before mapping (omitted if '--noqc' is specified)", action="store_true")
    parser.add_argument("-q", "--qval", help="Threshould of MACS2 (default: 0.05)", type=float, default=0.05)
    parser.add_argument("--macsdir", help="Output direcoty of macs2 (default: 'macs2')", type=str, default="macs")
    parser.add_argument("--mapparam", help="Additional parameter for bowtie|bowtie2 (shouled be quated)", type=str, default="")
    parser.add_argument("--parse2wigparam", help="Additional parameter for parse2wig+ (shouled be quated)", type=str, default="")
    parser.add_argument("--spikein", help="Spike-in mode", action="store_true")
    parser.add_argument("--build_spikein", help="(For Spike-in mode) Genome build of spikein genome (e.g., mm39)", type=str)
    parser.add_argument("--Ddir_spikein", help="(For Spike-in mode) Directory of spikein genome data", type=str)
    parser.add_argument("--spikein_simple", help="Spikein: Use ChIP samples only", action="store_true")
    parser.add_argument("--spikein_constant", help="Scaling Constant for the number of reads after normalization (default: 100)", type=int, default=100)
    parser.add_argument("-p", "--threads", help="Number of CPUs (default: 12)", type=int, default=12)
    parser.add_argument("--pair", help="(If inputs are BAM files) Specify if it is paired end", action="store_true")
    parser.add_argument("--threads_comparative", help="Number of CPUs for --comparative option (default: 8)", type=int, default=8)
    parser.add_argument("--outputpvalue", help="Output ChIP/Input -log(p) distribution as a begraph format", action="store_true")
    parser.add_argument("--comparative", help="Compare bigWigs and peaks among samples by churros_compare", action="store_true")
    parser.add_argument("-D", "--outputdir", help="Output directory (default: 'Churros_result')", type=str, default="Churros_result")
    parser.add_argument("--preset", help="Preset parameters for mapping reads ([scer|T2T])", type=str, default="")
    parser.add_argument("-v", "--version", help="Print version information and quit", action='version', version="churros version " + __version__)

    args = parser.parse_args()
    #    print(args)

    if args.preset != "":
        if args.preset != "scer" and args.preset != "T2T":
            print ("Error: specify [scer|T2T] for --preset option.")
            exit()

    exec_churros(args)
    print ("churros finished.")
